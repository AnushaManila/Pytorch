{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+qWjxLTkyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127876cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot array as an image\n",
    "def imshow(npimg):\n",
    "    plt.imshow(npimg)\n",
    "    plt.show()\n",
    "# create an array(16X16) of zeros and set a random coordinate (i,j) to 1\n",
    "def create_fake_dataset(imgsz):\n",
    "    imgs = np.zeros((numimgs, imgsz, imgsz))\n",
    "    coordinates = np.zeros((numimgs, 2))\n",
    "    for i in range(numimgs):\n",
    "        rand_coord = np.ravel((np.random.randint(5, size=(1, 2))).tolist())\n",
    "        imgs[i, rand_coord[0], rand_coord[1]] = 1\n",
    "        coordinates[i] = rand_coord\n",
    "    imshow(imgs[10]) #display 10th image\n",
    "    return imgs, coordinates\n",
    "\n",
    "numimgs = 10000\n",
    "imgs, coordinates = create_fake_dataset(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape to vector\n",
    "X = (imgs.reshape(numimgs, -1) - np.mean(imgs)) / np.std(imgs)\n",
    "np.mean(X), np.std(X)\n",
    "y = coordinates.reshape(numimgs, -1)\n",
    "\n",
    "#split data to train, test\n",
    "i = int(0.8*numimgs)\n",
    "X_train = Variable(torch.from_numpy(X[:i]).float())\n",
    "y_train = Variable(torch.from_numpy(y[:i]).float())\n",
    "X_test = Variable(torch.from_numpy(X[i:]).float())\n",
    "y_test = Variable(torch.from_numpy(y[i:]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple NN with one hidden layer for localization of non-zero pixel\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,X):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b would be sufficient\n",
    "        self.main = nn.Sequential(nn.Linear(X.shape[-1], 256), nn.ReLU(True),nn.Dropout(p=0.2),nn.Linear(256,y.shape[-1]))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "model = Net(X)\n",
    "# Loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.03, momentum= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.0728, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0561, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0988, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0563, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0996, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0289, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0698, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0123, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0487, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0235, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0565, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0414, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0732, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0428, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0721, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0274, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0574, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0119, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0452, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0448, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0182, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0548, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0208, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0552, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0133, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0473, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0375, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0369, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0107, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0412, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0140, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0430, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0112, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0413, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0370, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0339, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0358, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0392, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0047, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0366, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0023, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0338, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0019, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0308, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0040, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0332, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0339, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0325, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0036, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0314, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0305, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0306, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0020, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0315, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0312, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0306, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0297, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0297, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0295, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0026, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0302, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0307, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0286, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0292, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0281, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0281, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0287, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0277, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0280, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0282, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0276, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0271, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0276, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0268, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0268, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0264, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0272, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0264, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0271, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0009, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0271, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0269, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0270, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0262, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0265, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0263, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0254, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0261, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0268, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0259, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0258, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0252, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0253, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0252, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0256, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0260, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.0246, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0249, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0246, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0254, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0244, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0251, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0249, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0241, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0247, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0243, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0244, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0244, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0245, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0248, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0250, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0254, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "max_epochs = 100\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    # clear the gradients of all optimized variables\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(X_train)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, y_train)\n",
    "    # backward pass: compute gradient of the loss with respect to model parameters\n",
    "    loss.backward()\n",
    "    # perform a single optimization step (parameter update)\n",
    "    optimizer.step()\n",
    "    print ('loss:',loss)\n",
    "\n",
    "    # Validating the model\n",
    "    model.eval()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(X_test)\n",
    "    # calculate the batch loss\n",
    "    val_loss = criterion(output, y_test)\n",
    "    print ('val_loss:',val_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
