{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot array as an image\n",
    "def imshow(npimg):\n",
    "    plt.imshow(npimg)\n",
    "    plt.show()\n",
    "# create an array(16X16) of zeros and set a random coordinate (i,j) to 1\n",
    "def create_fake_dataset(imgsz):\n",
    "    imgs = np.zeros((numimgs, imgsz, imgsz))\n",
    "    coordinates = np.zeros((numimgs, 2))\n",
    "    for i in range(numimgs):\n",
    "        rand_coord = np.ravel((np.random.randint(5, size=(1, 2))).tolist())\n",
    "        imgs[i, rand_coord[0], rand_coord[1]] = 1\n",
    "        coordinates[i] = rand_coord\n",
    "    return imgs, coordinates\n",
    "\n",
    "numimgs = 10000\n",
    "imgs, coordinates = create_fake_dataset(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape to vector\n",
    "X = (imgs.reshape(numimgs, -1) - np.mean(imgs)) / np.std(imgs)\n",
    "np.mean(X), np.std(X)\n",
    "y = coordinates.reshape(numimgs, -1)\n",
    "\n",
    "#split data to train, test\n",
    "i = int(0.8*numimgs)\n",
    "X_train = Variable(torch.from_numpy(X[:i]).float())\n",
    "y_train = Variable(torch.from_numpy(y[:i]).float())\n",
    "X_test = Variable(torch.from_numpy(X[i:]).float())\n",
    "y_test = Variable(torch.from_numpy(y[i:]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple NN with one hidden layer for localization of non-zero pixel\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,X):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b would be sufficient\n",
    "        self.main = nn.Sequential(nn.Linear(X.shape[-1], 256), nn.ReLU(True),nn.Dropout(p=0.2),nn.Linear(256,y.shape[-1]))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "model = Net(X)\n",
    "# Loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.003, momentum= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(5.9689, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(5.5123, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(5.4756, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(4.6733, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(4.6400, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(3.6922, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(3.6629, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(2.7601, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2.7351, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(2.0214, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2.0056, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(1.5531, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1.5398, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(1.3601, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1.3615, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(1.3820, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1.3943, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(1.5141, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1.5349, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(1.6400, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1.6706, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(1.6682, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1.7129, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(1.5575, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1.5968, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(1.3212, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1.3578, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(1.0132, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1.0511, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.6975, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.7355, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.4296, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.4664, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.2377, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.2725, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.1299, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1625, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0939, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1280, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.1078, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1441, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.1469, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1822, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.1898, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.2263, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.2211, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.2604, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.2324, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.2720, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.2225, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.2639, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.1955, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.2373, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.1587, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.2028, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.1204, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1630, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0880, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1350, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0660, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1128, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0560, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1035, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0566, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1056, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0635, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1143, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0721, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1226, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0779, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1263, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0783, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1268, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0723, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1226, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0609, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.1103, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0465, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0935, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0317, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0793, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0651, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0100, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0545, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0052, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0479, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0044, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0449, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0065, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0480, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0102, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0485, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0141, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0530, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0173, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0563, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0582, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0190, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0565, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0176, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0545, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0153, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0523, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0126, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0498, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0101, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0466, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0080, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0461, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0066, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0438, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0426, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0056, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0436, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0057, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0457, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0059, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0060, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0058, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0451, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0053, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0446, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0045, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0433, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0037, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0435, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0028, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0427, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0021, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0411, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0405, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0395, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0398, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0012, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0406, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0014, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0405, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0406, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0394, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0017, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0394, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0016, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0400, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0015, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0407, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0013, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0392, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0010, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0388, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0008, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0385, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0006, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0397, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.0392, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0388, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0382, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0382, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0384, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0378, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0382, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0381, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0381, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0375, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0380, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0384, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0002, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0371, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0371, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0003, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0368, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0004, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0374, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0370, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n",
      "loss: tensor(0.0380, grad_fn=<MseLossBackward>)\n",
      "val_loss: tensor(0.0005, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "max_epochs = 100\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    # clear the gradients of all optimized variables\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(X_train)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, y_train)\n",
    "    # backward pass: compute gradient of the loss with respect to model parameters\n",
    "    loss.backward()\n",
    "    # perform a single optimization step (parameter update)\n",
    "    optimizer.step()\n",
    "    print ('loss:',loss)\n",
    "\n",
    "    # Validating the model\n",
    "    model.eval()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(X_test)\n",
    "    # calculate the batch loss\n",
    "    val_loss = criterion(output, y_test)\n",
    "    print ('val_loss:',val_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
