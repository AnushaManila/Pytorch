{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYTmloxcUOagAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117f13c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot array as an image\n",
    "def imshow(npimg):\n",
    "    plt.imshow(npimg)\n",
    "    plt.show()\n",
    "# create an array(16X16) of zeros and set a random coordinate (i,j) to 1\n",
    "def create_fake_dataset(imgsz):\n",
    "    imgs = np.zeros((numimgs, imgsz, imgsz))\n",
    "    coordinates = np.zeros((numimgs, 2))\n",
    "    for i in range(numimgs):\n",
    "        rand_coord = np.ravel((np.random.randint(15, size=(1, 2))).tolist())\n",
    "        imgs[i, rand_coord[0], rand_coord[1]] = 1\n",
    "        coordinates[i] = rand_coord\n",
    "    imshow(imgs[19]) #display random image\n",
    "    return imgs, coordinates\n",
    "\n",
    "numimgs = 10000\n",
    "imgs, coordinates = create_fake_dataset(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reshape to vector\n",
    "X = (imgs.reshape(numimgs, -1) - np.mean(imgs)) / np.std(imgs)\n",
    "np.mean(X), np.std(X)\n",
    "y = coordinates.reshape(numimgs, -1)\n",
    "\n",
    "#split data to train, test\n",
    "i = int(0.8*numimgs)\n",
    "X_train = Variable(torch.from_numpy(X[:i]).float())\n",
    "y_train = Variable(torch.from_numpy(y[:i]).float())\n",
    "X_test = Variable(torch.from_numpy(X[i:]).float())\n",
    "y_test = Variable(torch.from_numpy(y[i:]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple NN with one hidden layer for localization of non-zero pixel\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self,X):\n",
    "        super(Net, self).__init__()\n",
    "        # an affine operation: y = Wx + b would be sufficient\n",
    "        self.main = nn.Sequential(nn.Linear(X.shape[-1], 256), nn.ReLU(True),nn.Dropout(p=0.2),nn.Linear(256,y.shape[-1]))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "model = Net(X)\n",
    "# Loss function\n",
    "criterion = torch.nn.MSELoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.003, momentum= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss: 66.96849060058594\n",
      "val_loss: 62.47347640991211\n",
      "*****\n",
      "Epoch: 1\n",
      "loss: 62.01192092895508\n",
      "val_loss: 53.92576217651367\n",
      "*****\n",
      "Epoch: 2\n",
      "loss: 53.53828048706055\n",
      "val_loss: 43.69968032836914\n",
      "*****\n",
      "Epoch: 3\n",
      "loss: 43.38658142089844\n",
      "val_loss: 33.654788970947266\n",
      "*****\n",
      "Epoch: 4\n",
      "loss: 33.44675827026367\n",
      "val_loss: 25.304122924804688\n",
      "*****\n",
      "Epoch: 5\n",
      "loss: 25.191768646240234\n",
      "val_loss: 19.6275634765625\n",
      "*****\n",
      "Epoch: 6\n",
      "loss: 19.693235397338867\n",
      "val_loss: 16.967164993286133\n",
      "*****\n",
      "Epoch: 7\n",
      "loss: 17.170124053955078\n",
      "val_loss: 16.998899459838867\n",
      "*****\n",
      "Epoch: 8\n",
      "loss: 17.362524032592773\n",
      "val_loss: 18.820940017700195\n",
      "*****\n",
      "Epoch: 9\n",
      "loss: 19.34454345703125\n",
      "val_loss: 21.195709228515625\n",
      "*****\n",
      "Epoch: 10\n",
      "loss: 21.830135345458984\n",
      "val_loss: 22.924585342407227\n",
      "*****\n",
      "Epoch: 11\n",
      "loss: 23.65122413635254\n",
      "val_loss: 23.216747283935547\n",
      "*****\n",
      "Epoch: 12\n",
      "loss: 23.959291458129883\n",
      "val_loss: 21.89349365234375\n",
      "*****\n",
      "Epoch: 13\n",
      "loss: 22.627756118774414\n",
      "val_loss: 19.3303279876709\n",
      "*****\n",
      "Epoch: 14\n",
      "loss: 19.96105194091797\n",
      "val_loss: 16.205259323120117\n",
      "*****\n",
      "Epoch: 15\n",
      "loss: 16.834524154663086\n",
      "val_loss: 13.183670997619629\n",
      "*****\n",
      "Epoch: 16\n",
      "loss: 13.707513809204102\n",
      "val_loss: 10.736279487609863\n",
      "*****\n",
      "Epoch: 17\n",
      "loss: 11.227561950683594\n",
      "val_loss: 9.070239067077637\n",
      "*****\n",
      "Epoch: 18\n",
      "loss: 9.504450798034668\n",
      "val_loss: 8.158084869384766\n",
      "*****\n",
      "Epoch: 19\n",
      "loss: 8.584040641784668\n",
      "val_loss: 7.822772979736328\n",
      "*****\n",
      "Epoch: 20\n",
      "loss: 8.232579231262207\n",
      "val_loss: 7.837367534637451\n",
      "*****\n",
      "Epoch: 21\n",
      "loss: 8.229996681213379\n",
      "val_loss: 7.983326435089111\n",
      "*****\n",
      "Epoch: 22\n",
      "loss: 8.383048057556152\n",
      "val_loss: 8.08750057220459\n",
      "*****\n",
      "Epoch: 23\n",
      "loss: 8.501160621643066\n",
      "val_loss: 8.036736488342285\n",
      "*****\n",
      "Epoch: 24\n",
      "loss: 8.426691055297852\n",
      "val_loss: 7.779155731201172\n",
      "*****\n",
      "Epoch: 25\n",
      "loss: 8.156872749328613\n",
      "val_loss: 7.316819190979004\n",
      "*****\n",
      "Epoch: 26\n",
      "loss: 7.694934844970703\n",
      "val_loss: 6.690575122833252\n",
      "*****\n",
      "Epoch: 27\n",
      "loss: 7.065402984619141\n",
      "val_loss: 5.9660444259643555\n",
      "*****\n",
      "Epoch: 28\n",
      "loss: 6.355602741241455\n",
      "val_loss: 5.2195563316345215\n",
      "*****\n",
      "Epoch: 29\n",
      "loss: 5.62706995010376\n",
      "val_loss: 4.5188164710998535\n",
      "*****\n",
      "Epoch: 30\n",
      "loss: 4.902944087982178\n",
      "val_loss: 3.9158735275268555\n",
      "*****\n",
      "Epoch: 31\n",
      "loss: 4.2909746170043945\n",
      "val_loss: 3.435858726501465\n",
      "*****\n",
      "Epoch: 32\n",
      "loss: 3.830446481704712\n",
      "val_loss: 3.0765278339385986\n",
      "*****\n",
      "Epoch: 33\n",
      "loss: 3.4368813037872314\n",
      "val_loss: 2.8119184970855713\n",
      "*****\n",
      "Epoch: 34\n",
      "loss: 3.1808736324310303\n",
      "val_loss: 2.602792501449585\n",
      "*****\n",
      "Epoch: 35\n",
      "loss: 2.9582736492156982\n",
      "val_loss: 2.407604932785034\n",
      "*****\n",
      "Epoch: 36\n",
      "loss: 2.764226198196411\n",
      "val_loss: 2.193816661834717\n",
      "*****\n",
      "Epoch: 37\n",
      "loss: 2.530937433242798\n",
      "val_loss: 1.9458067417144775\n",
      "*****\n",
      "Epoch: 38\n",
      "loss: 2.3103387355804443\n",
      "val_loss: 1.6638166904449463\n",
      "*****\n",
      "Epoch: 39\n",
      "loss: 2.0333340167999268\n",
      "val_loss: 1.365053653717041\n",
      "*****\n",
      "Epoch: 40\n",
      "loss: 1.7124593257904053\n",
      "val_loss: 1.0758719444274902\n",
      "*****\n",
      "Epoch: 41\n",
      "loss: 1.4030961990356445\n",
      "val_loss: 0.8206046223640442\n",
      "*****\n",
      "Epoch: 42\n",
      "loss: 1.1651781797409058\n",
      "val_loss: 0.6173322200775146\n",
      "*****\n",
      "Epoch: 43\n",
      "loss: 0.9682766795158386\n",
      "val_loss: 0.47565147280693054\n",
      "*****\n",
      "Epoch: 44\n",
      "loss: 0.8158813118934631\n",
      "val_loss: 0.39391112327575684\n",
      "*****\n",
      "Epoch: 45\n",
      "loss: 0.7589609622955322\n",
      "val_loss: 0.36218005418777466\n",
      "*****\n",
      "Epoch: 46\n",
      "loss: 0.7238761782646179\n",
      "val_loss: 0.3657194674015045\n",
      "*****\n",
      "Epoch: 47\n",
      "loss: 0.7309477925300598\n",
      "val_loss: 0.3876410126686096\n",
      "*****\n",
      "Epoch: 48\n",
      "loss: 0.7563667893409729\n",
      "val_loss: 0.4124009609222412\n",
      "*****\n",
      "Epoch: 49\n",
      "loss: 0.7748239040374756\n",
      "val_loss: 0.42816469073295593\n",
      "*****\n",
      "Epoch: 50\n",
      "loss: 0.8042231202125549\n",
      "val_loss: 0.4279599189758301\n",
      "*****\n",
      "Epoch: 51\n",
      "loss: 0.8017455339431763\n",
      "val_loss: 0.41020771861076355\n",
      "*****\n",
      "Epoch: 52\n",
      "loss: 0.7936491370201111\n",
      "val_loss: 0.37712910771369934\n",
      "*****\n",
      "Epoch: 53\n",
      "loss: 0.7527258396148682\n",
      "val_loss: 0.3334573805332184\n",
      "*****\n",
      "Epoch: 54\n",
      "loss: 0.7017828822135925\n",
      "val_loss: 0.28568384051322937\n",
      "*****\n",
      "Epoch: 55\n",
      "loss: 0.6501766443252563\n",
      "val_loss: 0.2395036220550537\n",
      "*****\n",
      "Epoch: 56\n",
      "loss: 0.6120949983596802\n",
      "val_loss: 0.1986638605594635\n",
      "*****\n",
      "Epoch: 57\n",
      "loss: 0.5789462924003601\n",
      "val_loss: 0.16553300619125366\n",
      "*****\n",
      "Epoch: 58\n",
      "loss: 0.5613566637039185\n",
      "val_loss: 0.14039872586727142\n",
      "*****\n",
      "Epoch: 59\n",
      "loss: 0.5127050280570984\n",
      "val_loss: 0.12225865572690964\n",
      "*****\n",
      "Epoch: 60\n",
      "loss: 0.5005052089691162\n",
      "val_loss: 0.10924653708934784\n",
      "*****\n",
      "Epoch: 61\n",
      "loss: 0.4851714074611664\n",
      "val_loss: 0.0990157350897789\n",
      "*****\n",
      "Epoch: 62\n",
      "loss: 0.46669071912765503\n",
      "val_loss: 0.08971966803073883\n",
      "*****\n",
      "Epoch: 63\n",
      "loss: 0.46514055132865906\n",
      "val_loss: 0.08009973913431168\n",
      "*****\n",
      "Epoch: 64\n",
      "loss: 0.44542667269706726\n",
      "val_loss: 0.07044685631990433\n",
      "*****\n",
      "Epoch: 65\n",
      "loss: 0.42822426557540894\n",
      "val_loss: 0.06084583327174187\n",
      "*****\n",
      "Epoch: 66\n",
      "loss: 0.437812864780426\n",
      "val_loss: 0.05218562111258507\n",
      "*****\n",
      "Epoch: 67\n",
      "loss: 0.4061780571937561\n",
      "val_loss: 0.04523104056715965\n",
      "*****\n",
      "Epoch: 68\n",
      "loss: 0.40017077326774597\n",
      "val_loss: 0.04059414938092232\n",
      "*****\n",
      "Epoch: 69\n",
      "loss: 0.38993194699287415\n",
      "val_loss: 0.038583580404520035\n",
      "*****\n",
      "Epoch: 70\n",
      "loss: 0.38721197843551636\n",
      "val_loss: 0.03895473852753639\n",
      "*****\n",
      "Epoch: 71\n",
      "loss: 0.38060957193374634\n",
      "val_loss: 0.041030820459127426\n",
      "*****\n",
      "Epoch: 72\n",
      "loss: 0.3868831396102905\n",
      "val_loss: 0.044016048312187195\n",
      "*****\n",
      "Epoch: 73\n",
      "loss: 0.38885587453842163\n",
      "val_loss: 0.04708255082368851\n",
      "*****\n",
      "Epoch: 74\n",
      "loss: 0.38312605023384094\n",
      "val_loss: 0.049408700317144394\n",
      "*****\n",
      "Epoch: 75\n",
      "loss: 0.3844643831253052\n",
      "val_loss: 0.05046537145972252\n",
      "*****\n",
      "Epoch: 76\n",
      "loss: 0.3959517478942871\n",
      "val_loss: 0.049813657999038696\n",
      "*****\n",
      "Epoch: 77\n",
      "loss: 0.38787156343460083\n",
      "val_loss: 0.047519784420728683\n",
      "*****\n",
      "Epoch: 78\n",
      "loss: 0.3830643594264984\n",
      "val_loss: 0.043943796306848526\n",
      "*****\n",
      "Epoch: 79\n",
      "loss: 0.37975138425827026\n",
      "val_loss: 0.039597004652023315\n",
      "*****\n",
      "Epoch: 80\n",
      "loss: 0.37108495831489563\n",
      "val_loss: 0.034972384572029114\n",
      "*****\n",
      "Epoch: 81\n",
      "loss: 0.36132651567459106\n",
      "val_loss: 0.030537689104676247\n",
      "*****\n",
      "Epoch: 82\n",
      "loss: 0.3605743944644928\n",
      "val_loss: 0.026547687128186226\n",
      "*****\n",
      "Epoch: 83\n",
      "loss: 0.359008252620697\n",
      "val_loss: 0.023146744817495346\n",
      "*****\n",
      "Epoch: 84\n",
      "loss: 0.35529038310050964\n",
      "val_loss: 0.020406203344464302\n",
      "*****\n",
      "Epoch: 85\n",
      "loss: 0.35611867904663086\n",
      "val_loss: 0.01829613745212555\n",
      "*****\n",
      "Epoch: 86\n",
      "loss: 0.35615402460098267\n",
      "val_loss: 0.01664149761199951\n",
      "*****\n",
      "Epoch: 87\n",
      "loss: 0.3549073338508606\n",
      "val_loss: 0.015331636182963848\n",
      "*****\n",
      "Epoch: 88\n",
      "loss: 0.3491634726524353\n",
      "val_loss: 0.01419781893491745\n",
      "*****\n",
      "Epoch: 89\n",
      "loss: 0.35309654474258423\n",
      "val_loss: 0.01313022617250681\n",
      "*****\n",
      "Epoch: 90\n",
      "loss: 0.34929409623146057\n",
      "val_loss: 0.012125873938202858\n",
      "*****\n",
      "Epoch: 91\n",
      "loss: 0.34996914863586426\n",
      "val_loss: 0.011200587265193462\n",
      "*****\n",
      "Epoch: 92\n",
      "loss: 0.34238725900650024\n",
      "val_loss: 0.010407350026071072\n",
      "*****\n",
      "Epoch: 93\n",
      "loss: 0.347267746925354\n",
      "val_loss: 0.009792928583920002\n",
      "*****\n",
      "Epoch: 94\n",
      "loss: 0.3483850955963135\n",
      "val_loss: 0.009421488270163536\n",
      "*****\n",
      "Epoch: 95\n",
      "loss: 0.34475794434547424\n",
      "val_loss: 0.009272435680031776\n",
      "*****\n",
      "Epoch: 96\n",
      "loss: 0.3363882899284363\n",
      "val_loss: 0.009335257112979889\n",
      "*****\n",
      "Epoch: 97\n",
      "loss: 0.3445931375026703\n",
      "val_loss: 0.009515311568975449\n",
      "*****\n",
      "Epoch: 98\n",
      "loss: 0.3434388339519501\n",
      "val_loss: 0.009702986106276512\n",
      "*****\n",
      "Epoch: 99\n",
      "loss: 0.35045236349105835\n",
      "val_loss: 0.009857720695436\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "max_epochs = 100\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(max_epochs):\n",
    "    print('Epoch:', epoch)\n",
    "    model.train()\n",
    "    # clear the gradients of all optimized variables\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(X_train)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, y_train)\n",
    "    print ('loss:',loss.item())\n",
    "    # backward pass: compute gradient of the loss with respect to model parameters\n",
    "    loss.backward()\n",
    "    # perform a single optimization step (parameter update)\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    # Validating the model\n",
    "    model.eval()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(X_test)\n",
    "    # calculate the batch loss\n",
    "    val_loss = criterion(output, y_test)\n",
    "    print ('val_loss:',val_loss.item())\n",
    "    print ('*****')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
